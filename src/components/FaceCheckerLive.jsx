import { useEffect, useRef, useState } from "react";



const FaceCheckerLive = ({
    /** props: **/

    onApproach, //'ê°€ê¹Œì›€' ì¡°ê±´ì„ ë§Œì¡±í–ˆì„ ë•Œ ì‹¤í–‰í•  í•¨ìˆ˜
    onLeave, // ê°ì§€ë˜ë˜ ì–¼êµ´ì´ í™”ë©´ì—ì„œ ì‚¬ë¼ì¡Œì„ ë•Œ ì‹¤í–‰í•  í•¨ìˆ˜

    // width, height: ë‚´ë¶€ ì²˜ë¦¬ìš© ë¹„ë””ì˜¤ í•´ìƒë„ (ë‚®ì„ìˆ˜ë¡ ê°€ë³ê³  ë¹ ë¦„)
    width = 60,
    height = 80,

    // approachThreshold: 'ì–¼êµ´ ë°•ìŠ¤ì˜ í™”ë©´ ê°€ë¡œë¹„ìœ¨' ì„ê³„ê°’ (0~1). í´ìˆ˜ë¡ ë” ê°€ê¹Œì›Œì•¼ íŠ¸ë¦¬ê±°
    approachThreshold = 0.08, //ì–¼êµ´ì´ í™”ë©´ ë„ˆë¹„/ë†’ì´ì˜ 8% ì´ìƒì„ ì°¨ì§€í•˜ë©´ 'ê°€ê¹Œì›€'ìœ¼ë¡œ íŒë‹¨í•˜ê² ë‹¤ëŠ” ì˜ë¯¸

    // smoothSamples: ìµœê·¼ Ní”„ë ˆì„ í‰ê· ìœ¼ë¡œ ë…¸ì´ì¦ˆ/í”ë“¤ë¦¼ ì™„í™”
    //// ê°’ì´ í¬ë©´ ë” ë¶€ë“œëŸ½ì§€ë§Œ ë°˜ì‘ì´ ì•½ê°„ ëŠë ¤ì§
    smoothSamples = 3,

    // minStreak: N í”„ë ˆì„ 'ì—°ì†'ìœ¼ë¡œ ì–¼êµ´ì´ ê°ì§€ë˜ì–´ì•¼ ì•ˆì •ëœ ê²ƒìœ¼ë¡œ íŒë‹¨. ìˆœê°„ì ì¸ ì˜¤íƒì§€ë¥¼ ë°©ì§€
    minStreak = 3,
    isFace,
    setIsFace,
}) => {

    const videoRef = useRef(null);      // <video> DOM ì°¸ì¡° (ë¸Œë¼ìš°ì € ì¹´ë©”ë¼(ì›¹ìº )ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ì˜ìƒì„ <video>ì— ê½‚ì•„ë‘¬ì•¼ í•¨. í™”ë©´ì— ì•ˆ ë³´ì—¬ë„ 'ì…ë ¥ ì†ŒìŠ¤'ë¡œ ì“°ì„) 
    const streamRef = useRef(null);     // getUserMediaë¡œ ë°›ì€ MediaStream(ì‹¤ì‹œê°„ ì˜ìƒ/ìŒì„± ë°ì´í„°) ì €ì¥ (ì •ë¦¬ìš©). ì™œ í•„ìš”? ì»´í¬ë„ŒíŠ¸ê°€ ì‚¬ë¼ì§ˆ ë•Œ ì¹´ë©”ë¼ë¥¼ ë°˜ë“œì‹œ êº¼ì•¼ í•¨

    const calledRef = useRef(false);    // ì½œë°±(onApproach) í•œ ë²ˆë§Œ í˜¸ì¶œí•˜ë„ë¡ ì ê¸ˆ. trueê°€ ë˜ë©´, ì–¼êµ´ì´ ê³„ì† ê°€ê¹Œì´ ìˆì–´ë„ onApproachê°€ ì¤‘ë³µ ì‹¤í–‰ ã„´ã„´
    const bufferRef = useRef([]);       // ìµœê·¼ ë°•ìŠ¤ë„ˆë¹„ ê°’ë“¤ ì €ì¥(í‰ê·  ë‚´ì„œ í”ë“¤ë¦¼ ì™„í™”)

    const faceStreakRef = useRef(0); // "ì—°ì†"ìœ¼ë¡œ ì–¼êµ´ì´ ê°ì§€ëœ í”„ë ˆì„ ìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤. (minStreakì™€ ë¹„êµìš©)
    const facePresentRef = useRef(false); // "í˜„ì¬ ì–¼êµ´ì´ ë³´ì´ëŠ” ì¤‘ì¸ì§€" ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” í”Œë˜ê·¸ì…ë‹ˆë‹¤. ì´ ê°’ì˜ 'ë³€í™” ì‹œì '(false -> true ë˜ëŠ” true -> false)ì„ ê°ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.

    const initedRef = useRef(false);//// ì»´í¬ë„ŒíŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸


    // ëª¨ë“ˆ ì§€ë¬¸ (ì‹¤ì œë¡œ ì´ íŒŒì¼ì´ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸ìš©)
    // console.log('[FaceChecker MODULE] LOADED');

    onApproach = () => {
        console.log("ğŸğŸğŸğŸğŸğŸì–¼êµ´ì¸ì‹ì™„_startPage");
        setIsFace(true);

    }
    onLeave = () => {
        console.log("ğŸ’™ğŸ’™ğŸ’™ğŸ’™ğŸ’™ğŸ’™ğŸ’™ì–¼êµ´ ì‚¬ë¼ì§_startPage ");
        setIsFace(false);

    }

    useEffect(() => {

        if (initedRef.current) return;   // ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
        initedRef.current = true; //// ì´ˆê¸°í™” ì‹œì‘ì„ ì•Œë¦¼


        // ì „ì—­ ê°ì²´(window)ì— MediaPipe ìŠ¤í¬ë¦½íŠ¸ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ ë°©ì–´ ì½”ë“œ
        if (!window.FaceDetection || !window.Camera) {
            console.error("MediaPipe scripts not loaded. Check index.html script tags.");
            return;// MediaPipe ì—†ì´ëŠ” ì‹¤í–‰ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì¤‘ë‹¨
        }


        /** 1. MediaPipe FaceDetection ì¸ìŠ¤í„´ìŠ¤ ìƒì„± */
        const faceDetection = new window.FaceDetection({
            // locateFile: MediaPipeê°€ í•„ìš”ë¡œ í•˜ëŠ” AI ëª¨ë¸ íŒŒì¼(.wasm ë“±)ì„ ì–´ë””ì„œ ê°€ì ¸ì˜¬ì§€ ì•Œë ¤ì¤ë‹ˆë‹¤.
            // ì—¬ê¸°ì„œëŠ” CDN(ì½˜í…ì¸  ì „ì†¡ ë„¤íŠ¸ì›Œí¬) ì£¼ì†Œë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, 
            // ë³„ë„ íŒŒì¼ì„ í”„ë¡œì íŠ¸ì— í¬í•¨í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
            locateFile: (file) =>
                `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`,
        });


        /** 2. FaceDetection ê°ì§€ ì˜µì…˜ ì„¤ì • */
        faceDetection.setOptions({
            model: "short",
            //"short": ê°€ê¹Œìš´ ì–¼êµ´(ì „ì‹œì²˜ëŸ¼ ëª¨ë‹ˆí„° ì•ì— ì„œëŠ” ìƒí™©)ì— ìµœì í™”. ë¹ ë¥´ê³  ê°€ë²¼ì›€.
            // "full": ë” ë„“ì€ ê±°ë¦¬/í™”ê°(ìµœëŒ€ 5m). ëŒ€ì‹  ë¦¬ì†ŒìŠ¤ ì¡°ê¸ˆ ë” ë“¦.

            minDetectionConfidence: 0.5, //ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0~1)
            //0.5ëŠ” "ì–¼êµ´ì´ë¼ê³  50% ì´ìƒ í™•ì‹ í•  ë•Œë§Œ" ê²°ê³¼ì— í¬í•¨ì‹œí‚¤ë¼ëŠ” ì˜ë¯¸
            // ë‚®ìœ¼ë©´ ë¯¼ê°í•´ì§€ì§€ë§Œ ì˜¤ë¥˜ê°€ ë§ì•„ì§€ê³ , ë†’ìœ¼ë©´ ê¹ê¹í•´ì§€ì§€ë§Œ ê°ì§€ë¥¼ ë†“ì¹  ìˆ˜
        });





        /**
         * 3. ê°ì§€ ê²°ê³¼ ì½œë°± (ê°€ì¥ ì¤‘ìš”)
         * MediaPipeê°€ ë§¤ í”„ë ˆì„ ë¶„ì„ì„ ëë‚¼ ë•Œë§ˆë‹¤ ì´ í•¨ìˆ˜(onResults)ê°€ í˜¸ì¶œë©ë‹ˆë‹¤.
         * 'results' ê°ì²´ì— ê°ì§€ ê²°ê³¼ê°€ ë‹´ê²¨ ì˜µë‹ˆë‹¤.
         */
        let lastTime = 0;
        // ëª©í‘œ FPS ì„¤ì •: 10 FPS (1000ms / 10 = 100ms)
        // ì´ ê°’ì„ ëŠ˜ë¦¬ë©´ (ì˜ˆ: 1000 / 5) ë” ëšëš ëŠê¹ë‹ˆë‹¤.
        const targetInterval = 1000 / 2;

        faceDetection.onResults((results) => {

            /* ì–¼êµ´ì´ í•˜ë‚˜ë¼ë„ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸ */
            // results.detections: ê°ì§€ëœ ëª¨ë“  ì–¼êµ´ì˜ ì •ë³´ ë°°ì—´.
            // ì´ ë°°ì—´ì´ ì¡´ì¬í•˜ê³ , ë°°ì—´ì˜ ê¸¸ì´ê°€ 0ë³´ë‹¤ í¬ë©´ 'ì–¼êµ´ì´ ìˆë‹¤'ê³  ë´…ë‹ˆë‹¤.
            const hasFace = results?.detections && results.detections.length > 0;


            // âœ… "ì–¼êµ´ ìƒíƒœì˜ ë³€í™”"ë¥¼ ê°ì§€í•˜ì—¬ ë¡œê¹… ë° onLeave í˜¸ì¶œ
            // [ë°©ê¸ˆ ì–¼êµ´ì´ ë‚˜íƒ€ë‚¬ì„ ë•Œ]
            if (hasFace && !facePresentRef.current) {
                facePresentRef.current = true;
                console.log("âœ… ì–¼êµ´ ì¸ì‹ë¨");
                onApproach();
            }
            // [ë°©ê¸ˆ ì–¼êµ´ì´ ì‚¬ë¼ì¡Œì„ ë•Œ]
            if (!hasFace && facePresentRef.current) {
                facePresentRef.current = false;
                console.log("âŒ ì–¼êµ´ ì‚¬ë¼ì§");


                // ì–¼êµ´ì´ ì‚¬ë¼ì¡Œìœ¼ë¯€ë¡œ onLeave propìœ¼ë¡œ ë°›ì€ í•¨ìˆ˜ë¥¼ ì‹¤í–‰
                if (typeof onLeave === "function") {
                    onLeave();
                }
            }


            // ì—°ì† ê°ì§€ í”„ë ˆì„ ìˆ˜(streak)ë¥¼ ê³„ì‚°
            if (hasFace) faceStreakRef.current++; // ì–¼êµ´ ìˆìœ¼ë©´ 1 ì¦ê°€
            else faceStreakRef.current = 0; // ì–¼êµ´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ë¦¬ì…‹


            // ì–¼êµ´ì´ ì™„ì „íˆ ì‚¬ë¼ì§€ë©´, ë‹¤ìŒ ê´€ëŒê°ì„ ìœ„í•´ ì¬ë¬´ì¥
            if (!hasFace) {
                calledRef.current = false;   // â† // â† '1íšŒ í˜¸ì¶œ ì ê¸ˆ'ì„ í•´ì œ. ì¬íŠ¸ë¦¬ê±° ì¤€ë¹„
                return;                      // ìˆ«ì ê³„ì‚°ì€ ì–¼êµ´ ìˆì„ ë•Œë§Œ í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ì¢…ë£Œ
            }



            // --- ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆì„ ë•Œë§Œ ì•„ë˜ ë¡œì§ ì‹¤í–‰ ---

            // ì²« ë²ˆì§¸ ê°ì§€ëœ ì–¼êµ´ì˜ ë°”ìš´ë”© ë°•ìŠ¤(ì–¼êµ´ ì˜ì—­ ì‚¬ê°í˜•) ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            // (ì¢Œí‘œëŠ” 0~1 ì‚¬ì´ì˜ ìƒëŒ€ê°’ì…ë‹ˆë‹¤)
            const box = results.detections[0].locationData?.relativeBoundingBox;
            if (!box) return; // ë°•ìŠ¤ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê³„ì‚° ì¤‘ì§€


            // ì–¼êµ´ì˜ 'ê·¼ì ‘ë„'ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            // ì–¼êµ´ ë°•ìŠ¤ì˜ ë„ˆë¹„(w)ì™€ ë†’ì´(h) ì¤‘ ë” í° ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            // (ì¹´ë©”ë¼ ì™œê³¡ì´ë‚˜ ì–¼êµ´ ê°ë„ì— ë”°ë¥¸ ë³€ë™ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤)
            const w = Number.isFinite(Number(box.width)) ? Number(box.width) : 0;
            const h = Number.isFinite(Number(box.height)) ? Number(box.height) : 0;
            const dim = Math.max(0, Math.min(1, Math.max(w, h)));// 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ê³ ì •


            // 'smoothSamples' ë§Œí¼ì˜ ìµœê·¼ Nê°œ ìƒ˜í”Œë¡œ 'í‰í™œí™”(Smoothing)' ì‘ì—…ì„ í•©ë‹ˆë‹¤.
            // (ì–¼êµ´ì´ ë¯¸ì„¸í•˜ê²Œ ë–¨ë¦¬ê±°ë‚˜ ê°’ì´ íŠ€ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤)       
            const buf = bufferRef.current; // ìµœê·¼ w ê°’ë“¤ì„ ìŒ“ì•„ë‘ 
            buf.push(dim); // í˜„ì¬ í”„ë ˆì„ì˜ 'ê·¼ì ‘ë„(dim)' ê°’ì„ ë²„í¼ì— ì¶”ê°€

            if (buf.length > smoothSamples) buf.shift(); // ë²„í¼ê°€ Nê°œë³´ë‹¤ ê¸¸ì–´ì§€ë©´ ê°€ì¥ ì˜¤ë˜ëœ ê°’ ì œê±°

            // ë²„í¼ì— ìŒ“ì¸ ê°’ë“¤ì˜ 'í‰ê· 'ì„ ëƒ…ë‹ˆë‹¤.
            const avg = buf.reduce((a, b) => a + b, 0) / buf.length;
            if (!Number.isFinite(avg)) return;// í‰ê·  ê³„ì‚°ì´ ì‹¤íŒ¨í•˜ë©´(ì˜ˆ: bufê°€ ë¹„ì–´ìˆìŒ) ì¤‘ì§€



            // ì´ë¯¸ ì½œë°±ì„ ì‹¤í–‰í–ˆë‹¤ë©´ ë” ì´ìƒ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ(í•œ ë²ˆë§Œ íŠ¸ë¦¬ê±°)
            if (calledRef.current) return;


            // [ì¡°ê±´ 1] ì—°ì† 4í”„ë ˆì„ ì´ìƒ ê°ì§€ë˜ê³  (ì•ˆì •ì )
            // [ì¡°ê±´ 2] í‰ê·  ê·¼ì ‘ë„(avg)ê°€ ì„¤ì •í•œ ì„ê³„ê°’(approachThreshold)ë³´ë‹¤ í¬ë©´ (ê°€ê¹Œì›€)
            if (faceStreakRef.current >= 4 && avg >= approachThreshold) {
                calledRef.current = true;
                onApproach && onApproach();// onApproach ì‹¤í–‰
            }
        });



        /** 4. ì¹´ë©”ë¼ ì´ˆê¸°í™” ë° ì‹œì‘ */
        // MediaPipeê°€ ì œê³µí•˜ëŠ” Camera ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        // ì´ ìœ í‹¸ì€ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì™€ì„œ 
        // ì§€ì •ëœ ì½œë°±(onFrame)ì„ ê³„ì† í˜¸ì¶œí•´ì£¼ëŠ” ë£¨í”„ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        const camera = new window.Camera(videoRef.current, {
            // onFrame: ì¹´ë©”ë¼ì—ì„œ ìƒˆ í”„ë ˆì„ì´ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ í˜¸ì¶œë  í•¨ìˆ˜
            onFrame: async () => {
                // í˜„ì¬ ë¹„ë””ì˜¤ í”„ë ˆì„(<video> íƒœê·¸ì˜ í˜„ì¬ ì´ë¯¸ì§€)ì„
                // faceDetection ì¸ìŠ¤í„´ìŠ¤(MediaPipe ì—”ì§„)ë¡œ ì „ì†¡(send)í•©ë‹ˆë‹¤.
                // ì´ 'send'ê°€ ì™„ë£Œë˜ë©´, ìœ„ì—ì„œ ì •ì˜í•œ 'onResults' ì½œë°±ì´ íŠ¸ë¦¬ê±°ë©ë‹ˆë‹¤.
                const now = performance.now(); // í˜„ì¬ ì‹œê°„


                // targetInterval ì‹œê°„ì´ ì§€ë‚˜ì§€ ì•Šì•˜ìœ¼ë©´ AI ë¶„ì„ ìš”ì²­ì„ ê±´ë„ˆëœœ
                if (now - lastTime > targetInterval) {
                    lastTime = now; // ì‹œê°„ ì—…ë°ì´íŠ¸

                    // AI ë¶„ì„ ìš”ì²­ (onResults íŠ¸ë¦¬ê±°)
                    await faceDetection.send({ image: videoRef.current });
                }
            },
            width,// propsë¡œ ë°›ì€ í•´ìƒë„
            height,
        });

        // ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
        const startCamera = async () => {
            try {
                // getUserMediaë¡œ ë¸Œë¼ìš°ì € ì¹´ë©”ë¼ ì ‘ê·¼ (ê¶Œí•œ í—ˆìš© í•„ìš”)
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width, height },
                    audio: false,
                });

                // ë‚˜ì¤‘ì— ì¹´ë©”ë¼ë¥¼ ë„ê¸° ìœ„í•´ stream ì •ë³´ë¥¼ refì— ì €ì¥
                streamRef.current = stream;

                // <video> ìš”ì†Œì˜ 'srcObject'ì— ë°›ì•„ì˜¨ streamì„ ì—°ê²°í•©ë‹ˆë‹¤.
                // (ì´ ìˆœê°„ë¶€í„° ë³´ì´ì§€ ì•ŠëŠ” <video>ê°€ ì›¹ìº  ì˜ìƒì„ ì¬ìƒí•˜ê¸° ì‹œì‘í•©ë‹ˆë‹¤)
                if (videoRef.current) {
                    videoRef.current.srcObject = stream;
                }
                camera.start(); // ë£¨í”„ ì‹œì‘
            } catch (err) {
                // ì‚¬ìš©ìê°€ ì¹´ë©”ë¼ ê¶Œí•œì„ ê±°ë¶€í–ˆê±°ë‚˜, ì¹´ë©”ë¼ê°€ ì—†ëŠ” ê²½ìš°
                console.error("getUserMedia error:", err);
            }
        };

        startCamera();



        /** 5. ì»´í¬ë„ŒíŠ¸ ì •ë¦¬ (Cleanup) í•¨ìˆ˜ */
        return () => {
            try {
                // ì¹´ë©”ë¼ ë£¨í”„ ì •ì§€
                camera && camera.stop && camera.stop();
            } catch (_) { }// ì´ë¯¸ ì •ì§€ëœ ê²½ìš° ë“± ì˜¤ë¥˜ ë¬´ì‹œ
            // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì •ì§€ (ì¹´ë©”ë¼ LED êº¼ì§)
            if (streamRef.current) {
                streamRef.current.getTracks().forEach((t) => t.stop());
                streamRef.current = null;
            }

        };
    }, [onApproach, width, height, approachThreshold, smoothSamples, minStreak]);





    return (



        <div
            style={{
                width: `${isFace ? ' 70%' : '0%'}`, height: `${isFace ? ' 80%' : '0%'}`, overflow: 'hidden'
                // border: '2px solid green'
            }}
        >
            <h1 style={{ display: 'none' }}>FaceChecker</h1>
            <video
                ref={videoRef}
                style={{ width: ' 100%', height: '100%', filter: 'grayscale(100%)', transform: 'scale(1.5)', }}
                autoPlay
                muted
                playsInline
                controls={false}
            />
        </div >


    )
}

export default FaceCheckerLive 
